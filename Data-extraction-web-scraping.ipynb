{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "reviews_header = []\n",
    "rating = []\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "        \n",
    "    for para in parsed_content.find_all(\"h2\", {\"class\": \"text_header\"}):\n",
    "        reviews_header.append(para.get_text())\n",
    "        \n",
    "    rating_header = []\n",
    "    for para in parsed_content.find_all(\"span\", {\"itemprop\": \"ratingValue\"}):\n",
    "        rating_header.append(para.get_text())\n",
    "    rating_header.pop(0)\n",
    "    rating = rating_header + rating\n",
    "        \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "'''base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "rating = []\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    \n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    rating_header = []\n",
    "    for para in parsed_content.find_all(\"span\", {\"itemprop\": \"ratingValue\"}):\n",
    "        rating_header.append(para.get_text())\n",
    "    rating_header.pop(0)\n",
    "    rating = rating_header + rating\n",
    "    print(f\"   ---> {len(rating)} total reviews\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 4\n",
    "page_size = 50\n",
    "\n",
    "rating = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser') \n",
    "    for para in parsed_content.find_all(\"span\", {\"itemprop\": \"ratingValue\"}):\n",
    "        rating.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(rating)} total reviews\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>reviews_heading</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  A rather empty and quiet fl...</td>\n",
       "      <td>\"very friendly cabin crew\"</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Easy check in and staff mem...</td>\n",
       "      <td>\"a good drinks and food service\"</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  Being a silver flyer and bo...</td>\n",
       "      <td>\"you should let me use the lounge\"</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  I find BA incredibly tacky and...</td>\n",
       "      <td>\"I find BA incredibly tacky\"</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  Flew ATL to LHR 8th Jan 202...</td>\n",
       "      <td>\"This flight was so disappointing\"</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>✅ Trip Verified | Decided to go in Club Europe...</td>\n",
       "      <td>\"the seat pitch is ridiculous\"</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>✅ Trip Verified | BA used to be a byword for q...</td>\n",
       "      <td>\"it’s become a last resort\"</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>✅ Trip Verified | Premium economy worse than m...</td>\n",
       "      <td>\"Unprofessional staff, uncomfortable seats\"</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>✅ Trip Verified | Flew Belfast to London with ...</td>\n",
       "      <td>\"started with a 2.5 hours delay\"\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>✅ Trip Verified | Naples to Gatwick. The onlin...</td>\n",
       "      <td>\"Boarding was chaotic\"</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews  \\\n",
       "0    ✅ Trip Verified |  A rather empty and quiet fl...   \n",
       "1    ✅ Trip Verified |  Easy check in and staff mem...   \n",
       "2    ✅ Trip Verified |  Being a silver flyer and bo...   \n",
       "3    Not Verified |  I find BA incredibly tacky and...   \n",
       "4    ✅ Trip Verified |  Flew ATL to LHR 8th Jan 202...   \n",
       "..                                                 ...   \n",
       "995  ✅ Trip Verified | Decided to go in Club Europe...   \n",
       "996  ✅ Trip Verified | BA used to be a byword for q...   \n",
       "997  ✅ Trip Verified | Premium economy worse than m...   \n",
       "998  ✅ Trip Verified | Flew Belfast to London with ...   \n",
       "999  ✅ Trip Verified | Naples to Gatwick. The onlin...   \n",
       "\n",
       "                                 reviews_heading rating  \n",
       "0                     \"very friendly cabin crew\"      6  \n",
       "1               \"a good drinks and food service\"      8  \n",
       "2             \"you should let me use the lounge\"      2  \n",
       "3                   \"I find BA incredibly tacky\"      2  \n",
       "4             \"This flight was so disappointing\"      7  \n",
       "..                                           ...    ...  \n",
       "995               \"the seat pitch is ridiculous\"      5  \n",
       "996                  \"it’s become a last resort\"      5  \n",
       "997  \"Unprofessional staff, uncomfortable seats\"      7  \n",
       "998         \"started with a 2.5 hours delay\"\\r\\n      1  \n",
       "999                       \"Boarding was chaotic\"     10  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(\n",
    "    {'reviews': reviews ,\n",
    "     'reviews_heading': reviews_header,\n",
    "     'rating' : rating\n",
    "    })\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('BA_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<meta content=\"2018-07-13\" itemprop=\"datePublished\"/>\n",
    "<div class=\"rating-10\" itemprop=\"reviewRating\" itemscope=\"\" itemtype=\"http://schema.org/Rating\">\n",
    "<span itemprop=\"ratingValue\">2</span>/<span itemprop=\"bestRating\">10</span>\n",
    "</div>\n",
    "<div class=\"body\" id=\"anchor590887\">\n",
    "<h2 class=\"text_header\">\"not sitting together\"</h2>\n",
    "<h3 class=\"text_sub_header userStatusWrapper\">\n",
    "<span itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
    "<span itemprop=\"name\">S Peel</span></span> (United Kingdom) <time datetime=\"2018-07-13\" itemprop=\"datePublished\">13th July 2018</time></h3>\n",
    "<div class=\"tc_mobile\">\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"body\" id=\"anchor585148\">\n",
    "<h2 class=\"text_header\">\"unexpected problem with the systems\"</h2>\n",
    "<h3 class=\"text_sub_header userStatusWrapper\">\n",
    "<span itemprop=\"author\" itemscope=\"\" itemtype=\"http://schema.org/Person\">\n",
    "<span itemprop=\"name\">Robert Dixon-Gough</span></span> (United Kingdom) <time datetime=\"2018-06-20\" itemprop=\"datePublished\">20th June 2018</time></h3>\n",
    "<div class=\"tc_mobile\">\n",
    "<div class=\"text_content\" itemprop=\"reviewBody\">✅ <strong><a href=\"https://www.airlinequality.com/verified-reviews/\"><em>Trip Verified</em></a></strong> |  Calgary to London. Cabin full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
